# -*- coding: utf-8 -*-
"""Métodos de ensamblado.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i7XMj6HYQpUKdF1HhIhfH0ZZaG1JtAQx

# **LADISLAO JORGE MAMANI PUMAYLLE**
## En este proyecto se usaron la base de datos "diabetes" y "Advertising" los cuales lo encontramos en este repositorio.
"""

import pandas as pd
data1=pd.read_csv("/content/diabetes.csv")
data1

#Separamos las variables predictoras de la variable de clasificación
v_numericas=data1.select_dtypes(["float64","int64"]).drop(["Outcome"],axis=1)
v_numericas=list(v_numericas)
v_numericas

#Almacenamos en un objeto las variables predictoras y la de clasificación
X=data1[v_numericas]
y=data1["Outcome"]

#Tomamos 80% de los datos para entrenamiento y 20% para prueba
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

#Estandarizamos datos
from sklearn.preprocessing import StandardScaler
data_estand=StandardScaler()
X_train=data_estand.fit_transform(X_train)
X_test=data_estand.transform(X_test)

#Ajuste de hiperparámetros con validación cruzada para el modelo SVM
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV, StratifiedKFold
import numpy as np

param_grid={"C":np.array([1,2,5]),"gamma":np.array(["scale","auto"])}
kfold=StratifiedKFold(n_splits=4)
grid=GridSearchCV(estimator=SVC(),param_grid=param_grid,
                  scoring="accuracy",cv=kfold)
grid_result=grid.fit(X_train,y_train)
grid_result.best_params_

#Importamos todas las funcionesnecesarias para entrenar diferentes modelos
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import (VotingClassifier,BaggingClassifier,
                              AdaBoostClassifier,StackingClassifier)

#Almacenamos los modelos dentro de una lista
modelos=[]
modelos.append(("SVC",SVC(C=2,gamma="auto")))
modelos.append(("k-NN",KNeighborsClassifier(n_neighbors=20)))
modelos.append(("RL",LogisticRegression()))
modelos.append(("DTC",DecisionTreeClassifier()))
modelos.append(("RFC",RandomForestClassifier(n_estimators=1000)))
modelos.append(("NB",GaussianNB()))
estimators=modelos[0:5]
modelos.append(("Voting",VotingClassifier(estimators=estimators,voting="hard")))
modelos.append(("Bagging",BaggingClassifier(n_estimators=1000)))
modelos.append(("Boosting",AdaBoostClassifier(n_estimators=500,learning_rate=1)))
modelos.append(("Stacking",StackingClassifier(estimators=estimators,
                                              final_estimator=LogisticRegression())))
modelos

#Aplicaremos validación cruzada para cada modelo en el entrenamiento
#Calculamos sus métricas
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import classification_report, accuracy_score
resultados1=[]
nombres=[]
for nombre, modelo in modelos:
  print(f"\n Empezando a entrenar el modelo {nombre}...\n")
  kFold=KFold(n_splits=5)
  cv_resultados=cross_val_score(modelo,X_train,y_train,cv=kfold,scoring="accuracy")
  modelo.fit(X_train,y_train)
  resultados1.append(cv_resultados)
  nombres.append(nombre)
  msg=" %s: %f (%f)" % (nombre,cv_resultados.mean(),cv_resultados.std())
  print(f"######Reporte de clasificación para {modelo} #########")
  y_pred=modelo.predict(X_test)
  print(classification_report(y_test,y_pred))
  print(msg)
  print(f"Accuracy: {accuracy_score(y_test,y_pred)}")

import matplotlib.pyplot as plt
fig=plt.figure(figsize=(10,10))
fig.suptitle("Comparación del acierto de algoritmos para clasificación")
ax=fig.add_subplot(111)
plt.boxplot(resultados1)
ax.set_xticklabels(nombres)
ax.set_ylabel("Porcentaje de aciertos de clasificación")
plt.show()



"""# **ENSAMBLE CON DIFERENTES MODELOS DE REGRESIÓN**"""

#Leyendo el dataset
data2=pd.read_csv("/content/Advertising.csv")
data2

#Separando variables independiente de la dependiente
X=data2[["TV","Radio","Newspaper"]]
y=data2["Sales"]

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)



#Importamos todas las funcionesnecesarias para entrenar diferentes modelos
from sklearn.svm import SVR
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import (VotingRegressor,BaggingRegressor,
                              AdaBoostRegressor,StackingRegressor)

#Almacenamos todos los modelos en una lista
modelos=[]
modelos.append(("SVR",SVR(C=1,gamma="scale")))
modelos.append(("Regresión Lineal",LinearRegression()))
modelos.append(("DTR",DecisionTreeRegressor()))
modelos.append(("RFR",RandomForestRegressor(n_estimators=7000)))
estimators=modelos[0:4]
modelos.append(("Voting",VotingRegressor(estimators=estimators)))
modelos.append(("Bagging",BaggingRegressor(n_estimators=750)))
modelos.append(("Boosting",AdaBoostRegressor(n_estimators=500,learning_rate=1,random_state=123)))
modelos.append(("Stacking",StackingRegressor(estimators=estimators,n_jobs=-1)))
modelos

# CReamos un diccionario con las métricas que evaluaremos
scoring={"mean_squared_error":"neg_mean_squared_error",
         "neg_root_mean_squared_error":"neg_root_mean_squared_error",
         "mean_absolute_error":"neg_mean_absolute_error", "r2":"r2"}
scoring

#Aplicamos validación cruzada y calculamos las métricas de desempeño
from sklearn.model_selection import cross_validate
resultados2=[]
nombres=[]
for nombre, modelo in modelos:
  print(f"\nEmpezando a entrenar el modelo {nombre}...\n")
  cv_resultados=cross_validate(modelo,X_train, y_train,cv=7,
                               scoring=scoring, n_jobs=-1)
  print(f" Error cuadrático medio: {str(-cv_resultados['test_mean_squared_error'].mean())}")
  print(f" Raíz del error cuadrático medio: {str(-cv_resultados['test_neg_root_mean_squared_error'].mean())}")
  print(f" Error absoluto medio: {str(-cv_resultados['test_mean_absolute_error'].mean())}")
  print(f" Coeficiente de determinación: {str(cv_resultados['test_r2'].mean())}")
  resultados2.append(cv_resultados)